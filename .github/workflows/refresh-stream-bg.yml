name: Refresh Cloudflare Stream Token (BG-only)

on:
  workflow_dispatch: {}
  push:
    branches: [ "test" ]

permissions:
  contents: write

concurrency:
  group: refresh-stream-bg
  cancel-in-progress: true

jobs:
  refresh:
    if: github.ref == 'refs/heads/test' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout test
        uses: actions/checkout@v4
        with:
          ref: test
          fetch-depth: 0

      - name: Ensure curl & jq
        run: |
          set -e
          if ! command -v curl >/dev/null 2>&1; then
            sudo apt-get update -y
            sudo apt-get install -y curl
          fi
          if ! command -v jq >/dev/null 2>&1; then
            sudo apt-get update -y
            sudo apt-get install -y jq
          fi
          curl --version | head -n1
          jq --version

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.x"

      - name: Install Python deps
        run: pip install pyyaml python-dateutil

      - name: Find newest film (by date/lastmod) + extract video_id
        id: pick
        run: |
          python - <<'PY'
          import re, os, glob, yaml, sys, datetime
          from dateutil import parser as dp

          def read_front_matter(path):
            with open(path, 'r', encoding='utf-8') as f:
              txt = f.read()
            m = re.match(r'^---\s*\n(.*?)\n---\s*\n', txt, re.S)
            if not m:
              return None, txt
            fm = yaml.safe_load(m.group(1)) or {}
            return fm, txt[m.end():]

          def parse_dt(v):
            try:
              dt = dp.parse(str(v))
            except Exception:
              return None
            # normalize to UTC
            if dt.tzinfo is None:
              dt = dt.replace(tzinfo=datetime.timezone.utc)
            else:
              dt = dt.astimezone(datetime.timezone.utc)
            return dt

          def file_date(fm, path):
            # prefer explicit front-matter
            for k in ('date','lastmod','Date','Lastmod'):
              if k in fm:
                dt = parse_dt(fm[k])
                if dt: return dt
            # fallback: filename like 2025-09-03*.md
            bn = os.path.basename(path)
            m = re.match(r'^(\d{4})-(\d{2})-(\d{2})', bn)
            if m:
              y, mo, d = map(int, m.groups())
              return datetime.datetime(y, mo, d, tzinfo=datetime.timezone.utc)
            # fallback: mtime
            mt = os.path.getmtime(path)
            return datetime.datetime.fromtimestamp(mt, tz=datetime.timezone.utc)

          files = sorted(glob.glob('content/films/*.md'))
          if not files:
            print("::error::No files in content/films"); sys.exit(1)

          candidates = []
          for p in files:
            fm, _ = read_front_matter(p)
            if not fm:
              continue
            vid = (fm.get('video_id') or fm.get('video') or '').strip()
            if not vid:
              continue
            dt = file_date(fm, p)
            candidates.append((dt, p, vid))

          if not candidates:
            print("::error::No film with video_id found"); sys.exit(1)

          print("â€” Candidates (UTC):")
          for dt, p, vid in candidates:
            print(f"  {dt.isoformat()}  {p}  (video_id={vid})")

          candidates.sort(key=lambda x: x[0], reverse=True)
          dt, latest_path, vid = candidates[0]
          print(f"Picked newest: {latest_path} @ {dt.isoformat()}  (video_id={vid})")

          out = os.environ["GITHUB_OUTPUT"]
          with open(out, "a", encoding="utf-8") as fh:
            fh.write(f"path={latest_path}\n")
            fh.write(f"video_id={vid}\n")
          PY

      - name: Require signed URLs for this video
        env:
          CF_API_TOKEN:  ${{ secrets.CF_API_TOKEN }}
          CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
          VID:           ${{ steps.pick.outputs.video_id }}
        run: |
          set -Eeuo pipefail
          BODY='{"requireSignedURLs": true}'
          echo "POST /accounts/${CF_ACCOUNT_ID}/stream/${VID}"
          RESP=$(curl -sS -X POST \
            -H "Authorization: Bearer ${CF_API_TOKEN}" \
            -H "Content-Type: application/json" \
            "https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/stream/${VID}" \
            --data "$BODY")
          echo "$RESP" | jq .
          echo "$RESP" | jq -e '.success == true' >/dev/null || {
            echo "CF error:"; echo "$RESP" | jq -r '.errors[]? | (.code|tostring) + " - " + .message'
            exit 1
          }

      - name: Create signed playback token (BG allowlist, 24h)
        id: sign
        env:
          CF_API_TOKEN:  ${{ secrets.CF_API_TOKEN }}
          CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
          VID:           ${{ steps.pick.outputs.video_id }}
        run: |
          set -Eeuo pipefail
          EXP=$(( $(date +%s) + 24*3600 ))
          BODY=$(jq -n --argjson exp "$EXP" \
            '{ exp: $exp, restrictions: { geo: { allow: ["BG"] } } }')
          echo "POST /accounts/${CF_ACCOUNT_ID}/stream/${VID}/token"
          echo "Request:"; echo "$BODY" | jq .
          RESP=$(curl -sS -X POST \
            -H "Authorization: Bearer ${CF_API_TOKEN}" \
            -H "Content-Type: application/json" \
            "https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/stream/${VID}/token" \
            --data "$BODY")
          echo "Response:"; echo "$RESP" | jq .
          echo "$RESP" | jq -e '.success == true' >/dev/null || {
            echo "CF error:"; echo "$RESP" | jq -r '.errors[]? | (.code|tostring) + " - " + .message'
            exit 1
          }
          echo "token=$(echo "$RESP" | jq -r '.result.token')" >> "$GITHUB_OUTPUT"

      - name: Write token into front matter (picked file only)
        env:
          FILEPATH: ${{ steps.pick.outputs.path }}
          TOKEN:    ${{ steps.sign.outputs.token }}
        run: |
          python - <<'PY'
          import re, yaml, sys, os
          path = os.environ['FILEPATH']
          token = os.environ['TOKEN']
          with open(path, 'r', encoding='utf-8') as f:
            txt = f.read()
          m = re.match(r'^---\s*\n(.*?)\n---\s*\n(.*)$', txt, re.S)
          if not m:
            print("::error::Front matter not found in " + path); sys.exit(1)
          fm = yaml.safe_load(m.group(1)) or {}
          body = m.group(2)
          fm['signed_token'] = token
          new_fm = yaml.safe_dump(fm, sort_keys=False, allow_unicode=True).strip()
          new_txt = f"---\n{new_fm}\n---\n{body}"
          with open(path, 'w', encoding='utf-8') as f:
            f.write(new_txt)
          print(f"Updated signed_token in {path}")
          PY

      - name: Commit update back to test
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          if [ -n "$(git status --porcelain)" ]; then
            git add -A
            git commit -m "chore(stream): BG-only token refresh for newest film"
            git push origin HEAD:test
          else
            echo "Nothing to commit."
          fi

      - name: Trigger Netlify build (branch deploy)
        if: success()
        env:
          HOOK: ${{ secrets.NETLIFY_BUILD_HOOK }}
        run: |
          if [ -n "${HOOK:-}" ]; then
            curl -sS -X POST -d '{}' "$HOOK" || true
          else
            echo "NETLIFY_BUILD_HOOK not set; skipping Netlify trigger."
          fi
